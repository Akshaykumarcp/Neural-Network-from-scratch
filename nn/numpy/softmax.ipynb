{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Calculates the softmax for each row of the input x.\n",
    "\n",
    "    code should work for a row vector and also for matrices of shape (m,n).\n",
    "\n",
    "    Argument:\n",
    "    x -- A numpy matrix of shape (m,n)\n",
    "\n",
    "    Returns:\n",
    "    s -- A numpy matrix equal to the softmax of x, of shape (m,n)\n",
    "    \"\"\"\n",
    "\n",
    "    # Apply exp() element-wise to x. Use np.exp(...).\n",
    "\n",
    "    # Create a vector x_sum that sums each row of x_exp. Use np.sum(..., axis = 1, keepdims = True).\n",
    "\n",
    "    # Compute softmax(x) by dividing x_exp by x_sum. It should automatically use numpy broadcasting.\n",
    "    print(f\"input x: {x}\")\n",
    "    x_exp = np.exp(x)\n",
    "    print(f\"x_exp: {x_exp}\")\n",
    "    x_sum = np.sum(x_exp, axis=1, keepdims=True)\n",
    "    print(f\"x_sum: {x_sum}\")\n",
    "\n",
    "    s = x_exp / x_sum\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input x: [[9 2 5 0 0]\n",
      " [7 5 0 0 0]]\n",
      "x_exp: [[8.10308393e+03 7.38905610e+00 1.48413159e+02 1.00000000e+00\n",
      "  1.00000000e+00]\n",
      " [1.09663316e+03 1.48413159e+02 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00]]\n",
      "x_sum: [[8260.88614278]\n",
      " [1248.04631753]]\n",
      "softmax(x) = [[9.80897665e-01 8.94462891e-04 1.79657674e-02 1.21052389e-04\n",
      "  1.21052389e-04]\n",
      " [8.78679856e-01 1.18916387e-01 8.01252314e-04 8.01252314e-04\n",
      "  8.01252314e-04]]\n"
     ]
    }
   ],
   "source": [
    "t_x = np.array([[9, 2, 5, 0, 0],\n",
    "                [7, 5, 0, 0 ,0]])\n",
    "print(\"softmax(x) = \" + str(softmax(t_x)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v2ipynb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
